{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creative machine learning - Neural networks\n",
    "\n",
    "### Author: Philippe Esling (esling@ircam.fr)\n",
    "\n",
    "In this course we will cover\n",
    "1. A [quick introduction](#intro) on the principles of neural networks\n",
    "2. An implementation for a [single neuron](#neuron) in Numpy and JAX.\n",
    "3. An exercise on [multi-layer perceptron (MLP)](#mlp) through manual derivation.\n",
    "4. An introduction on [using Pytorch](#pytorch) for defining networks\n",
    "5. An exercise on [audio classification](#audio) using an MLP with Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Introducing neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will cover more advanced models known as *neural networks*. The tutorial starts by performing a simple **single neuron** discrimination of two random distributions. We will exhibit the manual implementation using Numpy, and then simplify it with JAX. Then, we will study the typical **XOR problem** by using a more advanced 2-layer **perceptron**. Finally, we generalize the use of neural networks in order to perform classification on a given set of audio files, using the PyTorch library, which will provide simplified implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use relatively _low-level_ libraries to perform the first exercises (implementing your own neurons). To observe this idea in simple setups, we are going to use the `numpy` library and also initialize the homemade course library `cml` and style for future plotting and exercise. We also set the random generator to a fixed point with `rng = np.random.RandomState(1)`, to ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\ANACONDA\\envs\\ml_win\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\ANACONDA\\envs\\ml_win\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\ANACONDA\\envs\\ml_win\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"fe517645-60c3-4193-b8c2-b46c684c9514\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"fe517645-60c3-4193-b8c2-b46c684c9514\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\", \"https://unpkg.com/@holoviz/panel@1.4.1/dist/panel.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"fe517645-60c3-4193-b8c2-b46c684c9514\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'ace': '//cdnjs.cloudflare.com/ajax/libs/ace/1.4.7'}, 'shim': {'ace/ext-language_tools': {'deps': ['ace/ace']}, 'ace/ext-modelist': {'deps': ['ace/ace']}}});\n      require([\"ace/ace\"], function(ace) {\n\twindow.ace = ace\n\ton_load()\n      })\n      require([\"ace/ext-language_tools\"], function() {\n\ton_load()\n      })\n      require([\"ace/ext-modelist\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 3;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window.ace !== undefined) && (!(window.ace instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ace.js', 'https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ext-language_tools.js', 'https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ext-modelist.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ace.js\", \"https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ext-language_tools.js\", \"https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.11/ext-modelist.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.1/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\"/*\\n ~ CML // Creative Machine Learning ~\\n mml.css : CSS styling information for Panel and Bokeh\\n \\n This file defines the main CSS styling information for the CML course\\n \\n Author               :  Philippe Esling\\n                        <esling@ircam.fr>\\n*/\\n\\nbody {\\n  display: flex;\\n  height: 100vh;\\n  margin: 0px;\\n  overflow-x: hidden;\\n  overflow-y: hidden;\\n}\\n\\n.bk-root .bk, .bk-root .bk:before, .bk-root .bk:after {\\n  font-family: \\\"Josefin Sans\\\";\\n}\\n\\nimg {\\n  max-width: 100%;\\n}\\n\\n#container {\\n  padding:0px;\\n  height:100vh;\\n  width: 100vw;\\n  max-width: 100vw;\\n}\\n\\n#sidebar .mdc-list {\\n  padding-left: 5px;\\n  padding-right: 5px;\\n}\\n\\n.mdc-drawer-app-content {\\n  flex: auto;\\n  position: relative;\\n  overflow: hidden;\\n}\\n\\n.mdc-drawer {\\n  background: #FAFAFA; /* GRAY 50 */\\n}\\n\\n.mdc-drawer-app-content {\\n  margin-left: 0 !important;\\n}\\n\\n.title-bar {\\n  display: contents;\\n  justify-content: center;\\n  align-content: center;\\n  width: 100%;\\n}\\n\\n.mdc-top-app-bar .bk-menu {\\n  color: black\\n}\\n\\n.app-header {\\n  display: contents;\\n  padding-left: 10px;\\n  font-size: 1.25em;\\n}\\n\\nimg.app-logo {\\n  padding-right: 10px;\\n  font-size: 28px;\\n  height: 30px;\\n  max-width: inherit;\\n  padding-top: 12px;\\n  padding-bottom: 6px;\\n}\\n\\n#app-title {\\n  padding-right: 12px;\\n  padding-left: 12px;\\n}\\n\\n.title {\\n  font-family: \\\"Josefin Sans\\\";\\n  color: #fff;\\n  text-decoration: none;\\n  text-decoration-line: none;\\n  text-decoration-style: initial;\\n  text-decoration-color: initial;\\n  font-weight: 400;\\n  font-size: 2em;\\n  line-height: 2em;\\n  white-space: nowrap;\\n}\\n\\n.main-content {\\n  overflow-y: scroll;\\n  overflow-x: auto;\\n}\\n\\n#header {\\n  position: absolute;\\n  z-index: 7;\\n}\\n\\n#header-items {\\n  width: 100%;\\n  margin-left:15px;\\n}\\n\\n.pn-busy-container {\\n  align-items: center;\\n  justify-content: center;\\n  display: flex;\\n}\\n\\n.mdc-drawer__content {\\n  overflow-x: hidden;\\n}\\n.mdc-drawer__content, .main-content {\\n  padding: 12px;\\n}\\n\\n.main-content {\\n  height: calc(100vh - 88px);\\n  max-height: calc(100vh - 88px);\\n  padding-right: 32px;\\n}\\n\\nbutton.mdc-button.mdc-card-button {\\n  color: transparent;\\n  height: 50px;\\n}\\n\\np.mdc-button {\\n  display: none;\\n}\\n\\ndiv.mdc-card {\\n  border-radius: 0px\\n}\\n\\n.mdc-card .card-header {\\n  display: flex;\\n}\\n\\n.mdc-card-title {\\n  font-family: \\\"Josefin Sans\\\";\\n  font-weight: bold;\\n  align-items: center;\\n  display: flex !important;\\n  position: relative !important;\\n}\\n\\n.mdc-card-title:nth-child(2) {\\n  margin-left: -1.4em;\\n}\\n\\n.pn-modal {\\n  overflow-y: scroll;\\n  width: 100%;\\n  display: none;\\n  position: absolute;\\n  top: 0;\\n  left: 0;\\n}\\n\\n.pn-modal-content {\\n  font-family: \\\"Josefin Sans\\\";\\n  background-color: #0e0e0e;\\n  margin: auto;\\n  margin-top: 25px;\\n  margin-bottom: 25px;\\n  padding: 15px 20px 20px 20px;\\n  border: 1px solid #888;\\n  width: 80% !important;\\n}\\n\\n.pn-modal-close {\\n  position: absolute;\\n  right: 25px;\\n  z-index: 100;\\n}\\n\\n.pn-modal-close:hover,\\n.pn-modal-close:focus {\\n  color: #000;\\n  text-decoration: none;\\n  cursor: pointer;\\n}\\n\\n.custom_button_bokeh button.bk-btn.bk-btn-default {\\n    font-size:48pt;\\n    background-color: #05b7ff;\\n    border-color: #05b7ff;\\n}\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='263d21a4-dc1d-424d-981e-c6f6dfb0bb41'>\n",
       "  <div id=\"e8c07ba2-f849-4eac-9d2f-681c6e79f3c7\" data-root-id=\"263d21a4-dc1d-424d-981e-c6f6dfb0bb41\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"9f52f06a-f4f2-4096-a807-fe23dddc5ea7\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"263d21a4-dc1d-424d-981e-c6f6dfb0bb41\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"de00a597-e855-4238-ab8e-6fce6753aae1\",\"attributes\":{\"plot_id\":\"263d21a4-dc1d-424d-981e-c6f6dfb0bb41\",\"comm_id\":\"ce00f151c72b497cb721bfbecdaf4555\",\"client_comm_id\":\"22d91b012656424e8eaeac7f02d1414a\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"9f52f06a-f4f2-4096-a807-fe23dddc5ea7\",\"roots\":{\"263d21a4-dc1d-424d-981e-c6f6dfb0bb41\":\"e8c07ba2-f849-4eac-9d2f-681c6e79f3c7\"},\"root_ids\":[\"263d21a4-dc1d-424d-981e-c6f6dfb0bb41\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "263d21a4-dc1d-424d-981e-c6f6dfb0bb41"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Base imports\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cml.plot import initialize_bokeh\n",
    "from cml.panel import initialize_panel\n",
    "from jupyterthemes.stylefx import set_nb_theme\n",
    "from bokeh.io import show\n",
    "initialize_bokeh()\n",
    "initialize_panel()\n",
    "set_nb_theme(\"onedork\")\n",
    "rng = np.random.RandomState(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, to simplify your work, we provide sets of functions that allows fast problem definition and plotting functionnalities (from our `cml` library).\n",
    "\n",
    "  |**File**|*Explanation*|\n",
    "  |-------:|:---------|\n",
    "  |`scatter_boundary`|Plots the decision boundary of a single neuron with 2-dimensional inputs|\n",
    "  |`scatter_classes`|Plots (bi-dimensionnal) input patterns|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cml.plot import scatter_classes, scatter_boundary, center_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that a single neuron is only able to learn _linearly separable_ problems. To produce such classes of problems, we provide a script that draw a set of random 2-dimensional points, then choose a random line in this space that will act as the linear frontier between 2 classes (hence defining a linear 2-class problem). The variables that will be used by your code are the following.  \n",
    "\n",
    "```Python\n",
    "y_class       # classes of the observqtions \n",
    "x_inputs      # 2 x n final matrix of random input observations\n",
    "weights       # 2 x 1 vector of neuron weights\n",
    "bias          # 1 x 1 vector of bias\n",
    "```\n",
    "\n",
    "You can execute the code below to see our simple classification problem. (Note that running the same cell multiple times produces a different starting dataset). In order to have a well-defined classification problem, we can rely on the `make_blobs` function provided by `scikit-learn` in the `sklearn.datasets` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05bb90ae9504d598740395c88ad756f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'102fbe41-e0ce-4163-bf5c-077ff008fbef': {'version"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "# Properties of the problem\n",
    "n_observations = 200\n",
    "noise = 0.2\n",
    "c1_center = [-2, -1]\n",
    "c2_center = [2, 1]\n",
    "# Create points\n",
    "x_coords, y_class = make_blobs(n_samples=n_observations, centers=[c1_center, c2_center], n_features=2, cluster_std=0.45)\n",
    "x_inputs = x_coords + (noise * np.random.randn(n_observations, 2))\n",
    "# Plot the corresponding pattern\n",
    "plot = center_plot(scatter_classes(x_inputs, y_class))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous example does not allow us to know the exact values (slope and bias) of our ground truth separation line. Hence, we can define a more complex separation problem (with points laying almost right on the separation fronteer), but with known values for our ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7394916441563875\n",
      "0.6828661206058257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138aefe8c24241bb843b6bc3ba81d197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'09059dca-663a-4666-8840-26c42ea9c497': {'version"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of points to generate\n",
    "n_observations = 100;\n",
    "# Generate 2-dimensional random points\n",
    "x_inputs = np.random.rand(int(n_observations), 2) * 2 - 1;\n",
    "# Slope of separating line\n",
    "sep_slope = np.log(np.random.rand() * 10);\n",
    "sep_bias = np.random.rand() * 2 - 1;\n",
    "# Create the indexes for a two-class problem\n",
    "y_class = (x_inputs[:, 1] - x_inputs[:, 0] * sep_slope - sep_bias > 0) * 1;\n",
    "# Plot the corresponding pattern\n",
    "plot = center_plot(scatter_classes(x_inputs, y_class))\n",
    "print(sep_slope)\n",
    "print(sep_bias)\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"neuron\"></a>\n",
    "## Single neuron\n",
    "\n",
    "For the first parts of the tutorial, we will perform the simplest classification model possible in a neural network setting, a single neuron. We briefly recall here that; given an input vector $ \\mathbf{x} \\in \\mathbb{R}^{n} $, a single neuron computes the function  \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\bar{y}=\\phi\\left(\\sum_{i = 1}^{n}w_{i}.x_{i} + b\\right)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "with $ \\mathbf{w} \\in \\mathbb{R}^{n} $ a weight vector, $ b $ a bias and $ \\phi\\left( \\cdot \\right) $ an *activation function*. Therefore, if we consider the *threshold* activation function ($ \\mathbb{I}_{0}\\left(x\\right)=1 $ if $ x \\geq 0$), a single neuron simply performs an *affine transform* and then a *linear* discrimination of the space. \n",
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #410819; border-color: #cb2e47\">\n",
    "\n",
    "> **Important note**\n",
    "> The following implementation tries to remain as close as possible to the original neuron model by McCulloch & Pitts, notably by using the _threshold activation_ function. Although this leads to a very simple implementation (akin to using an _identity_ activation, note that it is not to be used afterwards.\n",
    "\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "As we will see later on, a **neural network** will simply be composed of _layers_ of these neurons, which produce successive computations\n",
    "\n",
    "<img src=\"images/02_feedforward_nn.png\" align=\"center\"/>\n",
    "\n",
    "Geometrically, a single neuron computes an hyperplane that separates the space. In order to learn, we have to adjust the weights and know \"how much wrong we are\". To do so, we consider that we know the desired output $ y_{j} $ of a system for a given example $ \\mathbf{x}_{j} $ (eg. a predicted value for a regression system, a class value for a classification system). Therefore, we define the MSE loss function $ \\mathcal{L}_{\\mathcal{D}} $ over a whole dataset as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_{\\mathcal{D}}=\\sum_{j=1}^{|\\mathcal{D}|}\\left\\Vert \\bar{y}_{j}-y_{j}\\right\\Vert ^{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "with $|\\mathcal{D}|$ being the size of our dataset. In order to know how to change the weights based on the value of the errors, we need to now \"how to change it to make it better\". Therefore, we should compute the sets of derivatives of the error given each parameter\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\Delta\\bar{\\mathbf{w}}=\\left(\\frac{\\delta\\mathcal{L}_{\\mathcal{D}}}{\\delta w_{1}},\\ldots,\\frac{\\delta\\mathcal{L}_{\\mathcal{D}}}{\\delta w_{n}}\\right)\n",
    "\\end{equation}\n",
    "$$ \n",
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Exercise (course)\n",
    ">   1. Perform the derivatives of the output given a single neuron\n",
    ">   2. Perform the derivatives for the bias as well\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training your own neuron\n",
    "\n",
    "We will start by training a single neuron to learn how to perform this discrimination with a linear problem (so that a single neuron is enough to solve it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1\n",
      " 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Learning rate\n",
    "eta = 1e-2;\n",
    "# Weight decay\n",
    "lambda_r = 0.1\n",
    "# Number of epochs\n",
    "n_epochs = 50\n",
    "# Initialize the weights\n",
    "weights = np.random.randn(1, 2);\n",
    "bias = np.random.randn(1, 1);\n",
    "# Save the weight history for plotting\n",
    "weights_history = np.zeros((n_epochs + 1, 2));\n",
    "bias_history = np.zeros((n_epochs + 1, 1));\n",
    "print(y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to update the following code loop to ensure that your neuron learns to separate between the classes \n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Exercise (course)\n",
    ">   1. Update the loop so that it computes the forward propagation error\n",
    ">   2. Update the loop to perform learning (based on back-propagation)\n",
    ">   3. Run the learning procedure, which should produce a result similar to that displayed on the website\n",
    ">   4. Perform multiple re-runs by **tweaking the hyperparameters** (learning rate, weight decay)\n",
    ">   5. What observations can you make on the learning process?\n",
    ">   6. (Optional) Change the input patterns, and confirm your observations.\n",
    ">   6. (Optional) Incorporate the bias in the weights to obtain a **vectorized** code.\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.71902691e-02 -9.22336492e-01 -1.28936933e+00 -1.34160993e+00\n",
      "  -2.13462848e+00 -1.01631312e+00 -2.14108324e+00 -1.32503182e-01\n",
      "   4.25157269e-01 -2.36779639e-01 -8.28558553e-01 -3.89139936e-01\n",
      "  -2.51654828e-01 -1.88486644e+00 -1.04217910e+00 -1.78002554e-01\n",
      "  -1.46011116e+00 -2.61991436e-03 -5.71956173e-01 -6.86240692e-01\n",
      "  -1.27619832e+00 -3.07388294e+00 -1.45532806e+00  1.71013511e-01\n",
      "  -1.34733672e+00 -1.36858990e+00 -1.56988355e+00  8.00547281e-01\n",
      "   6.60737950e-01  1.16505812e+00 -1.76531735e+00 -1.97897831e+00\n",
      "  -1.13018404e+00 -2.32076979e+00 -1.87772635e+00 -2.61555427e+00\n",
      "   1.03620912e+00  1.72855933e-01 -1.37260631e+00 -2.64476283e-01\n",
      "  -1.35227826e+00 -2.87463292e+00  9.10749775e-01 -6.36019965e-01\n",
      "  -2.13109613e+00 -1.82021283e+00 -9.85530233e-01 -1.52200336e+00\n",
      "  -7.92415420e-01 -1.73084818e+00 -4.07896904e-01 -6.39403904e-01\n",
      "  -9.79496903e-01 -1.75034465e+00  8.85376439e-01  1.72566168e-01\n",
      "  -1.50068602e+00 -2.22711315e+00 -1.30973658e+00 -9.62836760e-01\n",
      "  -6.47510439e-01 -1.25156568e+00 -2.53970959e+00 -1.61975916e+00\n",
      "   1.00528482e-01  2.12142531e-01 -1.71300426e+00 -1.63773971e+00\n",
      "  -1.55657198e+00 -1.36346292e+00 -2.40934388e+00 -2.72258682e-01\n",
      "  -1.63198876e+00 -1.99659113e+00  5.08933197e-01 -1.54140257e+00\n",
      "  -1.66394902e+00  2.72153225e-01  1.66207823e-01 -1.35501335e+00\n",
      "  -1.75600599e-01 -2.27353606e+00 -6.57272782e-01 -4.66036483e-01\n",
      "  -1.34106054e+00 -1.96431746e+00 -2.22554049e+00 -1.11373919e+00\n",
      "  -2.15068912e-01  7.59666061e-01  5.91608293e-02  1.92213574e-02\n",
      "  -1.86836837e+00  2.15893103e-01 -3.66576949e-01 -8.06643790e-01\n",
      "  -1.39635881e+00 -2.29048776e-01 -1.42334208e+00 -2.21104655e+00]]\n",
      "[[False False False False False False False False  True False False False\n",
      "  False False False False False False False False False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False False False False  True False False False False False\n",
      "  False False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False False False False False\n",
      "  False False False False False  True  True  True False  True False False\n",
      "  False False False False]]\n",
      "[[ 0.00321652 -0.8612853  -1.19789372 -1.2023576  -2.08307859 -0.93640465\n",
      "  -2.01188805  0.01368997  0.53220697 -0.10888682 -0.71810513 -0.24177756\n",
      "  -0.12553493 -1.81869327 -0.86401125 -0.13020085 -1.38019046  0.07209117\n",
      "  -0.53767725 -0.52963018 -1.19901375 -3.01320423 -1.40765978  0.26113569\n",
      "  -1.18690531 -1.22419395 -1.41665514  0.93938355  0.80687964  1.31558613\n",
      "  -1.61749773 -1.93928247 -0.99350835 -2.24307741 -1.73605916 -2.52943371\n",
      "   1.1619997   0.33737575 -1.34333979 -0.13194015 -1.32297407 -2.80005113\n",
      "   1.03474046 -0.57468658 -2.07317391 -1.76457345 -0.83608596 -1.39649455\n",
      "  -0.63357627 -1.62037124 -0.37400448 -0.61789104 -0.87832719 -1.65103181\n",
      "   1.00753843  0.25710296 -1.38371966 -2.1657867  -1.25181243 -0.90162621\n",
      "  -0.60105585 -1.19660401 -2.48366854 -1.52973464  0.25316405  0.28599189\n",
      "  -1.58984889 -1.55826755 -1.48479596 -1.30831315 -2.31259993 -0.21024065\n",
      "  -1.53181968 -1.93422192  0.59754987 -1.39301959 -1.60807686  0.41949094\n",
      "   0.25380866 -1.2704586  -0.0858267  -2.15908186 -0.62460681 -0.43274804\n",
      "  -1.27805854 -1.86486424 -2.15175795 -1.08131619 -0.12630866  0.86292944\n",
      "   0.16404365  0.184393   -1.73268979  0.35427545 -0.2363876  -0.64606537\n",
      "  -1.35567288 -0.13398482 -1.26652638 -2.14562189]]\n",
      "[[ True False False False False False False  True  True False False False\n",
      "  False False False False False  True False False False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False False False False  True False False False False False\n",
      "  False False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False False False False False\n",
      "  False False False False False  True  True  True False  True False False\n",
      "  False False False False]]\n",
      "[[ 0.04327471 -0.83396114 -1.13371288 -1.08550506 -2.05408489 -0.88756256\n",
      "  -1.89807305  0.12610959  0.59635883 -0.015408   -0.63778521 -0.12553257\n",
      "  -0.03384368 -1.77621765 -0.70765285 -0.12473287 -1.326927    0.10519129\n",
      "  -0.54305772 -0.40033901 -1.15056375 -2.9649164  -1.3896504   0.30933386\n",
      "  -1.04687692 -1.10145868 -1.28227905  1.0345049   0.91136422  1.41984963\n",
      "  -1.4870847  -1.9247746  -0.88156845 -2.18369787 -1.61124559 -2.45792605\n",
      "   1.24053973  0.46676769 -1.3462393  -0.03311762 -1.32603436 -2.73856583\n",
      "   1.11256186 -0.54989823 -2.03725929 -1.73423862 -0.71164472 -1.2928526\n",
      "  -0.50079775 -1.53106364 -0.38143638 -0.63653695 -0.80664212 -1.57371725\n",
      "   1.08361567  0.29918874 -1.28961434 -2.12520235 -1.22405389 -0.87372583\n",
      "  -0.59239499 -1.17265707 -2.44574885 -1.4638562   0.3703016   0.31601823\n",
      "  -1.48687882 -1.50372942 -1.43946509 -1.28304946 -2.23154403 -0.18831802\n",
      "  -1.45474601 -1.89478897  0.64074824 -1.26421564 -1.57904004  0.52914071\n",
      "   0.29930229 -1.21318051 -0.03456597 -2.06004245 -0.63090056 -0.44026176\n",
      "  -1.24444591 -1.78527114 -2.09759222 -1.08334132 -0.07576239  0.91962566\n",
      "   0.22946543  0.31602243 -1.61450631  0.4547084  -0.13911269 -0.51124694\n",
      "  -1.3458711  -0.07641861 -1.12968995 -2.10072355]]\n",
      "[[ True False False False False False False  True  True False False False\n",
      "  False False False False False  True False False False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False False False False  True False False False False False\n",
      "  False False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False False False False False\n",
      "  False False False False False  True  True  True False  True False False\n",
      "  False False False False]]\n",
      "[[ 0.0833329  -0.80663699 -1.06953204 -0.96865253 -2.02509119 -0.83872047\n",
      "  -1.78425805  0.23852921  0.6605107   0.07807081 -0.55746529 -0.00928757\n",
      "   0.05784757 -1.73374203 -0.55129445 -0.11926489 -1.27366354  0.1382914\n",
      "  -0.5484382  -0.27104785 -1.10211375 -2.91662857 -1.37164101  0.35753203\n",
      "  -0.90684853 -0.97872342 -1.14790296  1.12962625  1.01584879  1.52411312\n",
      "  -1.35667168 -1.91026672 -0.76962854 -2.12431833 -1.48643203 -2.3864184\n",
      "   1.31907976  0.59615962 -1.34913882  0.06570491 -1.32909466 -2.67708053\n",
      "   1.19038326 -0.52510989 -2.00134468 -1.70390379 -0.58720348 -1.18921066\n",
      "  -0.36801924 -1.44175604 -0.38886828 -0.65518286 -0.73495706 -1.49640269\n",
      "   1.15969291  0.34127451 -1.19550902 -2.08461801 -1.19629534 -0.84582545\n",
      "  -0.58373413 -1.14871012 -2.40782915 -1.39797776  0.48743915  0.34604456\n",
      "  -1.38390876 -1.44919128 -1.39413421 -1.25778578 -2.15048812 -0.16639538\n",
      "  -1.37767234 -1.85535603  0.68394662 -1.1354117  -1.55000321  0.63879048\n",
      "   0.34479591 -1.15590243  0.01669477 -1.96100304 -0.63719432 -0.44777549\n",
      "  -1.21083328 -1.70567805 -2.04342649 -1.08536644 -0.02521611  0.97632189\n",
      "   0.29488721  0.44765187 -1.49632282  0.55514134 -0.04183778 -0.37642851\n",
      "  -1.33606932 -0.0188524  -0.99285353 -2.0558252 ]]\n",
      "[[ True False False False False False False  True  True  True False False\n",
      "   True False False False False  True False False False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False  True False False  True False False False False False\n",
      "  False False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False  True False False False\n",
      "  False False False False False  True  True  True False  True False False\n",
      "  False False False False]]\n",
      "[[ 0.07817806 -0.81602287 -1.04177739 -0.89199988 -2.02221394 -0.82748732\n",
      "  -1.70332392  0.30040578  0.67306647  0.12345261 -0.51894733  0.05837776\n",
      "   0.1017172  -1.72067731 -0.44096284 -0.155336   -1.25443733  0.12607818\n",
      "  -0.5909991  -0.18875644 -1.08894136 -2.88769719 -1.38487597  0.35766611\n",
      "  -0.80883322 -0.8964224  -1.05311601  1.16733893  1.06340889  1.56700707\n",
      "  -1.26379963 -1.92208769 -0.6993644  -2.09185173 -1.39771438 -2.34019044\n",
      "   1.33945922  0.67094135 -1.38233315  0.11624575 -1.36261673 -2.63777626\n",
      "   1.21121209 -0.53936131 -1.99213437 -1.7025756  -0.50672347 -1.12310983\n",
      "  -0.28158137 -1.38698864 -0.43476742 -0.7093455  -0.70304382 -1.45249128\n",
      "   1.17914239  0.33577403 -1.1383665  -2.07026384 -1.20185357 -0.85432305\n",
      "  -0.61271435 -1.15828818 -2.39315909 -1.36573833  0.55159206  0.32910428\n",
      "  -1.31673556 -1.42722102 -1.38134902 -1.26516278 -2.09730462 -0.18650106\n",
      "  -1.33502981 -1.8441006   0.67649267 -1.0460008  -1.55125145  0.69453905\n",
      "   0.34248548 -1.13391449  0.02271239 -1.89248412 -0.67984007 -0.49323539\n",
      "  -1.21073103 -1.65777785 -2.01659711 -1.12004748 -0.01950624  0.97906147\n",
      "   0.31184955  0.5258507  -1.41378486  0.60291219  0.00818342 -0.28798888\n",
      "  -1.35737364 -0.00656343 -0.89710088 -2.03764616]]\n",
      "[[ True False False False False False False  True  True  True False  True\n",
      "   True False False False False  True False False False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False  True False False  True False False False False False\n",
      "  False False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False  True False False False\n",
      "  False False False False False  True  True  True False  True  True False\n",
      "  False False False False]]\n",
      "[[ 0.05475273 -0.83947442 -1.03220216 -0.84075813 -2.03016454 -0.8330661\n",
      "  -1.64508549  0.33403     0.66253678  0.14353492 -0.5021901   0.09798963\n",
      "   0.12058044 -1.72104499 -0.36243574 -0.20454163 -1.25137167  0.09635598\n",
      "  -0.6440461  -0.13549585 -1.09178171 -2.86960757 -1.40934491  0.33767821\n",
      "  -0.73946012 -0.84027937 -0.98554185  1.17655125  1.0815569   1.57907563\n",
      "  -1.19702533 -1.94315231 -0.65442821 -2.07393799 -1.33398789 -2.3093707\n",
      "   1.33298702  0.71421784 -1.42406831  0.14081761 -1.40471532 -2.61173378\n",
      "   1.20564927 -0.56814303 -1.99473188 -1.71316363 -0.45373753 -1.08005203\n",
      "  -0.22435896 -1.35265745 -0.49133502 -0.77194213 -0.69124901 -1.42727962\n",
      "   1.17251729  0.31100368 -1.10299165 -2.0680969  -1.22042891 -0.87685108\n",
      "  -0.65393195 -1.18051581 -2.38940764 -1.35097004  0.58616412  0.29447071\n",
      "  -1.27196425 -1.42108125 -1.38333652 -1.28505342 -2.0614579  -0.22177719\n",
      "  -1.31139223 -1.84553123  0.64864964 -0.98310341 -1.56468153  0.72126456\n",
      "   0.32044583 -1.12895068  0.00917149 -1.844211   -0.73259959 -0.54918578\n",
      "  -1.22437654 -1.62828393 -2.00386267 -1.16413323 -0.03314172  0.95880241\n",
      "   0.30659663  0.57267072 -1.35533576  0.62311268  0.0327449  -0.22900982\n",
      "  -1.38893065 -0.01456351 -0.82932548 -2.03230489]]\n",
      "[[ True False False False False False False  True  True  True False  True\n",
      "   True False False False False  True False False False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False  True False False  True False False False False False\n",
      "  False False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False  True False False False\n",
      "  False False False False False  True  True  True False  True  True False\n",
      "  False False False False]]\n",
      "[[ 0.0313274  -0.86292597 -1.02262692 -0.78951638 -2.03811514 -0.83864488\n",
      "  -1.58684705  0.36765421  0.65200709  0.16361724 -0.48543287  0.13760151\n",
      "   0.13944368 -1.72141266 -0.28390864 -0.25374727 -1.24830601  0.06663378\n",
      "  -0.69709309 -0.08223526 -1.09462205 -2.85151794 -1.43381384  0.31769031\n",
      "  -0.67008701 -0.78413634 -0.9179677   1.18576356  1.09970492  1.5911442\n",
      "  -1.13025104 -1.96421693 -0.60949202 -2.05602426 -1.27026141 -2.27855095\n",
      "   1.32651481  0.75749433 -1.46580348  0.16538946 -1.44681391 -2.58569129\n",
      "   1.20008644 -0.59692474 -1.99732939 -1.72375166 -0.40075159 -1.03699424\n",
      "  -0.16713654 -1.31832627 -0.54790262 -0.83453877 -0.67945421 -1.40206796\n",
      "   1.16589218  0.28623332 -1.06761681 -2.06592996 -1.23900424 -0.89937912\n",
      "  -0.69514954 -1.20274343 -2.3856562  -1.33620175  0.62073618  0.25983714\n",
      "  -1.22719294 -1.41494148 -1.38532401 -1.30494405 -2.02561119 -0.25705331\n",
      "  -1.28775464 -1.84696186  0.62080661 -0.92020603 -1.5781116   0.74799007\n",
      "   0.29840618 -1.12398687 -0.0043694  -1.79593788 -0.78535912 -0.60513616\n",
      "  -1.23802204 -1.59879001 -1.99112823 -1.20821898 -0.0467772   0.93854335\n",
      "   0.3013437   0.61949075 -1.29688666  0.64331317  0.05730638 -0.17003075\n",
      "  -1.42048766 -0.0225636  -0.76155008 -2.02696363]]\n",
      "[[ True False False False False False False  True  True  True False  True\n",
      "   True False False False False  True False False False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False  True False False  True False False False False False\n",
      "  False False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False False False False False\n",
      "  False False False False False  True  True  True False  True  True False\n",
      "  False False False False]]\n",
      "[[ 0.02178747 -0.87424618 -1.00375415 -0.73169881 -2.03742498 -0.83340847\n",
      "  -1.52413243  0.41147095  0.65559761  0.19452477 -0.45887124  0.18649725\n",
      "   0.16917769 -1.7130963  -0.19989493 -0.28766007 -1.23588926  0.05134681\n",
      "  -0.73542473 -0.021164   -1.08735883 -2.82837192 -1.44719486  0.31188784\n",
      "  -0.59528713 -0.72178094 -0.84531626  1.20863776  1.13066396  1.61745274\n",
      "  -1.05875529 -1.97549497 -0.55714534 -2.03147857 -1.20185583 -2.24252107\n",
      "   1.33517773  0.81099233 -1.495196    0.20044741 -1.47650484 -2.55467727\n",
      "   1.20934107 -0.61264603 -1.99161452 -1.72488035 -0.34055951 -0.9872221\n",
      "  -0.10257251 -1.27716728 -0.58919324 -0.88196124 -0.65785735 -1.36949707\n",
      "   1.17409845  0.27595157 -1.02500149 -2.05594893 -1.24655883 -0.90991787\n",
      "  -0.72255064 -1.21360041 -2.37483941 -1.31314796  0.66592542  0.24039298\n",
      "  -1.17621154 -1.40001242 -1.37784388 -1.31384307 -1.98444123 -0.27810603\n",
      "  -1.25641322 -1.83987388  0.60834366 -0.85187888 -1.58157947  0.7861814\n",
      "   0.29067066 -1.10957267 -0.00484925 -1.74283873 -0.82359855 -0.64596906\n",
      "  -1.24102107 -1.56264993 -1.97123919 -1.2392769  -0.0474277   0.93370959\n",
      "   0.30911971  0.67599089 -1.23340805  0.67527184  0.09214251 -0.10384979\n",
      "  -1.44038971 -0.01796118 -0.68840559 -2.01397398]]\n",
      "[[ True False False False False False False  True  True  True False  True\n",
      "   True False False False False  True False False False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False  True False False  True False False False False False\n",
      "  False False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False False False False False\n",
      "  False False False False False  True  True  True False  True  True False\n",
      "  False False False False]]\n",
      "[[ 0.01224754 -0.88556639 -0.98488139 -0.67388124 -2.03673482 -0.82817206\n",
      "  -1.4614178   0.4552877   0.65918812  0.22543229 -0.43230962  0.23539299\n",
      "   0.1989117  -1.70477993 -0.11588123 -0.32157287 -1.2234725   0.03605984\n",
      "  -0.77375637  0.03990725 -1.08009561 -2.80522589 -1.46057588  0.30608538\n",
      "  -0.52048725 -0.65942554 -0.77266482  1.23151195  1.16162299  1.64376128\n",
      "  -0.98725953 -1.98677301 -0.50479865 -2.00693289 -1.13345025 -2.20649119\n",
      "   1.34384065  0.86449034 -1.52458852  0.23550537 -1.50619576 -2.52366324\n",
      "   1.21859571 -0.62836731 -1.98589966 -1.72600904 -0.28036742 -0.93744996\n",
      "  -0.03800847 -1.2360083  -0.63048387 -0.92938371 -0.63626049 -1.33692617\n",
      "   1.18230472  0.26566981 -0.98238617 -2.0459679  -1.25411343 -0.92045662\n",
      "  -0.74995173 -1.22445739 -2.36402263 -1.29009418  0.71111466  0.22094881\n",
      "  -1.12523014 -1.38508335 -1.37036375 -1.32274209 -1.94327127 -0.29915875\n",
      "  -1.22507181 -1.8327859   0.5958807  -0.78355173 -1.58504734  0.82437274\n",
      "   0.28293513 -1.09515848 -0.0053291  -1.68973959 -0.86183799 -0.68680196\n",
      "  -1.24402009 -1.52650984 -1.95135015 -1.27033482 -0.0480782   0.92887584\n",
      "   0.31689573  0.73249103 -1.16992944  0.7072305   0.12697864 -0.03766883\n",
      "  -1.46029176 -0.01335876 -0.6152611  -2.00098433]]\n",
      "[[ True False False False False False False  True  True  True False  True\n",
      "   True False False False False  True False  True False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False  True False False  True False False False False False\n",
      "  False False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False False False False False\n",
      "  False False False False False  True  True  True False  True  True False\n",
      "  False False False False]]\n",
      "[[-0.00375588 -0.90171606 -0.97526569 -0.63169889 -2.04094639 -0.83036297\n",
      "  -1.41388447  0.48387676  0.65334112  0.24341893 -0.41701055  0.26862495\n",
      "   0.21594307 -1.70302609 -0.05232294 -0.35774605 -1.21897132  0.01514469\n",
      "  -0.81299128  0.08376542 -1.08018431 -2.78921925 -1.47760023  0.29280624\n",
      "  -0.46413086 -0.61341544 -0.71774794  1.24115489  1.17823096  1.65569144\n",
      "  -0.93299705 -2.00121382 -0.46751446 -1.9909517  -1.08158724 -2.18046409\n",
      "   1.34125666  0.90067088 -1.55509911  0.25699775 -1.53698744 -2.50140949\n",
      "   1.216704   -0.64864144 -1.98592572 -1.73223574 -0.2367685  -0.90169257\n",
      "   0.00893121 -1.20710436 -0.67244675 -0.97609447 -0.62486345 -1.31515467\n",
      "   1.17957876  0.24865203 -0.95263206 -2.04228345 -1.26650856 -0.93589031\n",
      "  -0.7799498  -1.23969918 -2.35914594 -1.27646776  0.74047941  0.19622597\n",
      "  -1.08816157 -1.3782053  -1.36982742 -1.3361735  -1.91328346 -0.32445601\n",
      "  -1.20451329 -1.83187969  0.57651079 -0.73228686 -1.59347267  0.84762867\n",
      "   0.26805124 -1.0891577  -0.01361961 -1.65001674 -0.90086087 -0.72829096\n",
      "  -1.2525658  -1.50142236 -1.93940391 -1.30264455 -0.05644854  0.91547229\n",
      "   0.31511959  0.77141901 -1.12219084  0.72537688  0.14844773  0.01064207\n",
      "  -1.48284871 -0.01732548 -0.56016508 -1.99481583]]\n",
      "[[False False False False False False False  True  True  True False  True\n",
      "   True False False False False  True False  True False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False  True False False  True False False False False False\n",
      "   True False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False False False False False\n",
      "  False False False False False  True  True  True False  True  True  True\n",
      "  False False False False]]\n",
      "[[-1.62449096e-02 -9.13387715e-01 -9.75070462e-01 -6.16934182e-01\n",
      "  -2.04603129e+00 -8.35715087e-01 -1.39589998e+00  4.91320316e-01\n",
      "   6.44854211e-01  2.46245890e-01 -4.14763457e-01  2.78405843e-01\n",
      "   2.18359798e-01 -1.70571304e+00 -2.83436790e-02 -3.79119448e-01\n",
      "  -1.22087733e+00  3.88633638e-04 -8.35317911e-01  9.85926611e-02\n",
      "  -1.08432808e+00 -2.78431209e+00 -1.48910514e+00  2.81272224e-01\n",
      "  -4.43042811e-01 -5.96916530e-01 -6.97069087e-01  1.23917982e+00\n",
      "   1.17950620e+00  1.65435514e+00 -9.12405778e-01 -2.01102043e+00\n",
      "  -4.55153643e-01 -1.98684233e+00 -1.06194803e+00 -2.17156942e+00\n",
      "   1.33358598e+00  9.11179075e-01 -1.57270122e+00  2.61416146e-01\n",
      "  -1.55473606e+00 -2.49392607e+00  1.20947287e+00 -6.62450352e-01\n",
      "  -1.98914883e+00 -1.73854712e+00 -2.21744271e-01 -8.89603088e-01\n",
      "   2.52427556e-02 -1.19785135e+00 -6.96160542e-01 -1.00168264e+00\n",
      "  -6.24197871e-01 -1.30906024e+00  1.17200231e+00  2.35450091e-01\n",
      "  -9.43240495e-01 -2.04375253e+00 -1.27610228e+00 -9.47200571e-01\n",
      "  -7.98080672e-01 -1.25062240e+00 -2.35975720e+00 -1.27413995e+00\n",
      "   7.48025349e-01  1.79548560e-01 -1.07528824e+00 -1.37886644e+00\n",
      "  -1.37339984e+00 -1.34617298e+00 -1.90283885e+00 -3.40883596e-01\n",
      "  -1.19908308e+00 -1.83482776e+00  5.61909242e-01 -7.13265447e-01\n",
      "  -1.60092716e+00  8.52272696e-01  2.55807009e-01 -1.09050509e+00\n",
      "  -2.25682420e-02 -1.63537506e+00 -9.23003890e-01 -7.51732837e-01\n",
      "  -1.26041112e+00 -1.49362655e+00 -1.93719236e+00 -1.32131886e+00\n",
      "  -6.53915265e-02  9.03268124e-01  3.08829253e-01  7.83312174e-01\n",
      "  -1.10439964e+00  7.27802330e-01  1.52962356e-01  2.75796139e-02\n",
      "  -1.49688109e+00 -2.42911904e-02 -5.39559416e-01 -1.99519455e+00]]\n",
      "[[False False False False False False False  True  True  True False  True\n",
      "   True False False False False  True False  True False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False  True False False  True False False False False False\n",
      "   True False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False False False False False\n",
      "  False False False False False  True  True  True False  True  True  True\n",
      "  False False False False]]\n",
      "[[-0.02873394 -0.92505937 -0.97487524 -0.60216947 -2.05111619 -0.8410672\n",
      "  -1.37791548  0.49876388  0.6363673   0.24907285 -0.41251637  0.28818674\n",
      "   0.22077653 -1.70839998 -0.00436442 -0.40049285 -1.22278335 -0.01436742\n",
      "  -0.85764454  0.1134199  -1.08847186 -2.77940492 -1.50061006  0.26973821\n",
      "  -0.42195477 -0.58041762 -0.67639023  1.23720476  1.18078144  1.65301885\n",
      "  -0.8918145  -2.02082703 -0.44279283 -1.98273296 -1.04230881 -2.16267476\n",
      "   1.32591529  0.92168727 -1.59030332  0.26583454 -1.57248468 -2.48644264\n",
      "   1.20224174 -0.67625927 -1.99237194 -1.74485849 -0.20672004 -0.8775136\n",
      "   0.0415543  -1.18859835 -0.71987434 -1.02727081 -0.62353229 -1.30296581\n",
      "   1.16442585  0.22224815 -0.93384893 -2.04522161 -1.28569599 -0.95851083\n",
      "  -0.81621154 -1.26154562 -2.36036846 -1.27181214  0.75557129  0.16287115\n",
      "  -1.0624149  -1.37952759 -1.37697225 -1.35617246 -1.89239424 -0.35731118\n",
      "  -1.19365287 -1.83777582  0.5473077  -0.69424403 -1.60838165  0.85691672\n",
      "   0.24356278 -1.09185249 -0.03151687 -1.62073337 -0.94514691 -0.77517471\n",
      "  -1.26825644 -1.48583073 -1.9349808  -1.33999318 -0.07433452  0.89106395\n",
      "   0.30253892  0.79520534 -1.08660845  0.73022778  0.15747698  0.04451716\n",
      "  -1.51091346 -0.0312569  -0.51895375 -1.99557327]]\n",
      "[[False False False False False False False  True  True  True False  True\n",
      "   True False False False False False False  True False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False  True False False  True False False False False False\n",
      "   True False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False False False False False\n",
      "  False False False False False  True  True  True False  True  True  True\n",
      "  False False False False]]\n",
      "[[-0.02543237 -0.92286832 -0.96543328 -0.58304299 -2.046881   -0.83481551\n",
      "  -1.358196    0.51534663  0.64334376  0.26234962 -0.40079118  0.30583566\n",
      "   0.23374852 -1.7020635   0.02153996 -0.40335735 -1.21508819 -0.01244231\n",
      "  -0.86192297  0.13387531 -1.08191878 -2.7703019  -1.49935362  0.27416871\n",
      "  -0.3985918  -0.56017917 -0.65373915  1.24929272  1.19477826  1.66625168\n",
      "  -0.86960603 -2.01945801 -0.424866   -1.97268699 -1.02096061 -2.14999311\n",
      "   1.33463995  0.94092834 -1.59298025  0.28012597 -1.57522012 -2.47521774\n",
      "   1.21101532 -0.67494169 -1.98687915 -1.74082978 -0.18672001 -0.86053845\n",
      "   0.0627983  -1.17393872 -0.72476245 -1.03387264 -0.61316589 -1.29046624\n",
      "   1.17291762  0.22556125 -0.91864425 -2.03873907 -1.2828698  -0.95615653\n",
      "  -0.81781982 -1.25949829 -2.35392352 -1.26158639  0.77268041  0.16392731\n",
      "  -1.04528826 -1.371345   -1.37058592 -1.35372434 -1.87826648 -0.3570384\n",
      "  -1.18136708 -1.83183413  0.55034113 -0.67265042 -1.60481397  0.87241348\n",
      "   0.24750674 -1.0835757  -0.02603027 -1.60351953 -0.94946955 -0.77999433\n",
      "  -1.26431726 -1.47260843 -1.9260227  -1.34288203 -0.06892163  0.89620019\n",
      "   0.31027224  0.81507507 -1.06648329  0.74412373  0.17163257  0.06615375\n",
      "  -1.51123905 -0.02454321 -0.49606408 -1.98832673]]\n",
      "[[False False False False False False False  True  True  True False  True\n",
      "   True False  True False False False False  True False False False  True\n",
      "  False False False  True  True  True False False False False False False\n",
      "   True  True False  True False False  True False False False False False\n",
      "   True False False False False False  True  True False False False False\n",
      "  False False False False  True  True False False False False False False\n",
      "  False False  True False False  True  True False False False False False\n",
      "  False False False False False  True  True  True False  True  True  True\n",
      "  False False False False]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af55fda2ee24cc2895bec4a8866b332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'68fc0fd7-7c9a-42aa-8ada-0b367800c86b': {'version"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbose = False\n",
    "weights_history[0] = weights\n",
    "bias_history[0] = bias\n",
    "# Update loop\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "\n",
    "    ######################\n",
    "    # Solution  \n",
    "    y_real = np.dot(weights, x_inputs.T) + bias \n",
    "    print(y_real)\n",
    "    y_bar = y_real > 0\n",
    "    print(y_bar)\n",
    "    if np.sum(np.abs(y_bar - y_class)) == 0:\n",
    "        break\n",
    "    error = y_class - y_bar\n",
    "    weights = weights + eta * (np.dot(error, x_inputs))\n",
    "    bias = bias + eta * (np.sum(error))\n",
    "    ######################\n",
    "    \n",
    "    weights_history[i + 1] = weights\n",
    "    bias_history[i + 1] = bias\n",
    "    \n",
    "    if (verbose):\n",
    "        print('%2d. error = %f, weights = %f, %f, %f' % (i, np.sum(np.abs(error)) / n_observations, bias[0, 0], weights[0, 0], weights[0, 1]))\n",
    "plot = center_plot(scatter_boundary(x_inputs, y_class, weights_history, bias_history, i + 1))\n",
    "plot\n",
    "plot\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "# ax.scatter(x_inputs[y_class == 0, 0], x_inputs[y_class == 0, 1], color='red', label='Class 0')\n",
    "# ax.scatter(x_inputs[y_class == 1, 0], x_inputs[y_class == 1, 1], color='blue', label='Class 1')\n",
    "# ax.set_xlabel('x1')\n",
    "# ax.set_ylabel('x2')\n",
    "# ax.set_title('Decision boundary')\n",
    "# x_vals = np.linspace(-1, 1, 100)\n",
    "# y_vals = (-weights[0, 0] / weights[0, 1] * x_vals - bias / weights[0, 1]).flatten()\n",
    "# ax.plot(x_vals, y_vals, color='black', linestyle='--')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron implementation in `JAX`\n",
    "\n",
    "As seen in the previous course, the `NumPy` implementation requires us to perform manual differentiation of our loss function to understand how to update the parameters. However, the recent [`JAX`](https://github.com/google/jax) library provides **automatic differentiation** on top of the `NumPy` library. If you have not yet completed the set of [tutorials](https://jax.readthedocs.io/en/latest/), we strongly encourage you to do so. We will introduce a few more functions compared to last time, but we try to keep the implementation as simple as possible on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, random\n",
    "\n",
    "seed = np.random.randint(0, 1e9)\n",
    "np.random.seed(23)\n",
    "key = random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep our previousmy generated dataset but we will rely on `jnp.ndarray` instead of `np.ndarray`, by simply casting the arrays to JAX-compliant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_jax = jnp.asarray(x_inputs)\n",
    "y_jax = jnp.asarray(y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also keep the same hyperparameters as previously (see `eta`, `lambda_r` and `n_epochs` above) and randomly initialize our parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01\n",
    "# Perform key splitting\n",
    "key_w, key_b, key = random.split(key, 3)\n",
    "# Initialize the weights\n",
    "weights = random.normal(key_w, (1, 2));\n",
    "bias = random.normal(key_b, (1, 1));\n",
    "# Save the weight history for plotting\n",
    "weights_history = jnp.zeros((n_epochs + 1, 2));\n",
    "bias_history = jnp.zeros((n_epochs + 1, 1));\n",
    "# Record the first \n",
    "weights_history = weights_history.at[0].set(weights[0])\n",
    "bias_history = bias_history.at[0].set(bias[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed earlier, the original model by McCulloch & Pitts has several issues regarding its use for numerical optimization (as it was originally observed from a neuroscience point of view)\n",
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #410819; border-color: #cb2e47\">\n",
    "\n",
    "> **Changes from the `NumPy` implementation**\n",
    ">   1. (Smoothness) Our _activation function_ will change from _identity_ to sigmoid, i.e. $ \\phi(\\mathbf{x}) = \\frac{1}{1 + e^{-\\mathbf{x}}} $\n",
    ">   2. (Outliers) Our _loss function_ will change from $ L_{1} $ to $ L_{2} $ (MSE - Mean Squared Error)\n",
    "\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "As discussed in the previous course, for using the very handy `grad` function provided by `JAX`, we need to define the whole forward function that we want to derive given our parameters. Hence this function also needs to **contain the forward pass**. This is summarized in the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced<ConcreteArray(24.41105842590332, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(24.411058, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AE820>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED05C60; to 'JaxprTracer' at 0x000001D0EED05990>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFA9F80>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "# Single neuron full function\n",
    "def loss_function(x, y, w, b):\n",
    "    # Forward pass\n",
    "    y_bar = jax.nn.sigmoid(jnp.dot(w, x.T) + b)\n",
    "    # Error computation\n",
    "    error = jnp.sum((y_bar - y) ** 2)\n",
    "    print(error)\n",
    "    return error\n",
    "\n",
    "grad_FUNCTION = grad(loss_function, argnums=[2, 3])\n",
    "dW, dB = grad_FUNCTION(x_jax, y_jax, weights, bias)\n",
    "# Gradient of the loss\n",
    "grad_loss_function = grad(loss_function, argnums=[2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can now define the main training loop, which is almost exactly similar to the previously defined one minus the gradient computation operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced<ConcreteArray(24.41105842590332, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(24.411058, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AEE30>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED441D0; to 'JaxprTracer' at 0x000001D0EED44180>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFB0AB0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(22.958829879760742, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(22.95883, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF0F0>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55760; to 'JaxprTracer' at 0x000001D0EED55710>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAA3E0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(21.631763458251953, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(21.631763, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF060>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED557B0; to 'JaxprTracer' at 0x000001D0EED55850>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAD630>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(20.42574691772461, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(20.425747, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AEE70>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55800; to 'JaxprTracer' at 0x000001D0EED55670>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAFFC0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(19.33383560180664, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(19.333836, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF0E0>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55A80; to 'JaxprTracer' at 0x000001D0EED55350>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFA9B20>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(18.347412109375, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(18.347412, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF000>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED553A0; to 'JaxprTracer' at 0x000001D0EED55760>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFA9F80>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(17.45709800720215, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(17.457098, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF020>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED552B0; to 'JaxprTracer' at 0x000001D0EED547C0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAF2A0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(16.653411865234375, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(16.653412, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF140>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED549A0; to 'JaxprTracer' at 0x000001D0EED55AD0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAEE40>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(15.927206039428711, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(15.927206, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF050>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55530; to 'JaxprTracer' at 0x000001D0EED55990>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFB1E60>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(15.26991081237793, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(15.269911, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF180>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED550D0; to 'JaxprTracer' at 0x000001D0EED553A0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFA98F0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(14.673677444458008, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(14.673677, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF090>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED54E00; to 'JaxprTracer' at 0x000001D0EED55A30>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFB1E60>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(14.13144302368164, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(14.131443, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF010>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55800; to 'JaxprTracer' at 0x000001D0EED55670>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFB0CE0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(13.636924743652344, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(13.636925, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF080>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55300; to 'JaxprTracer' at 0x000001D0EED55C10>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAAED0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(13.184589385986328, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(13.184589, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF1A0>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED54720; to 'JaxprTracer' at 0x000001D0EED55760>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAD860>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(12.769599914550781, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(12.7696, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AEF70>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55D00; to 'JaxprTracer' at 0x000001D0EED55DF0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAC280>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(12.387750625610352, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(12.387751, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AEF40>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED550D0; to 'JaxprTracer' at 0x000001D0EED55BC0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAF2A0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(12.035394668579102, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(12.035395, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF190>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED54590; to 'JaxprTracer' at 0x000001D0EED54E50>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAE9E0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(11.709371566772461, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(11.709372, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF030>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED552B0; to 'JaxprTracer' at 0x000001D0EED55F30>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAACA0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(11.406942367553711, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(11.406942, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF170>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55800; to 'JaxprTracer' at 0x000001D0EED55620>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAC050>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(11.125728607177734, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(11.125729, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AEF20>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55B20; to 'JaxprTracer' at 0x000001D0EED55DA0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAC4B0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(10.86366081237793, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(10.863661, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF0F0>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED54C20; to 'JaxprTracer' at 0x000001D0EED550D0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAE580>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(10.618925094604492, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(10.618925, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF060>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED561B0; to 'JaxprTracer' at 0x000001D0EED56200>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAC280>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(10.389936447143555, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(10.389936, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AEE70>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED54E00; to 'JaxprTracer' at 0x000001D0EED55530>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAA1B0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(10.175289154052734, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(10.175289, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF0E0>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55760; to 'JaxprTracer' at 0x000001D0EED556C0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAE580>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(9.97374439239502, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(9.973744, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF000>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED550D0; to 'JaxprTracer' at 0x000001D0EED544F0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAFFC0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(9.784193992614746, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(9.784194, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF020>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55F30; to 'JaxprTracer' at 0x000001D0EED56480>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAACA0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(9.605650901794434, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(9.605651, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF140>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED562A0; to 'JaxprTracer' at 0x000001D0EED55E90>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAD630>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(9.43722915649414, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(9.437229, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF050>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55B20; to 'JaxprTracer' at 0x000001D0EED563E0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAF4D0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(9.278128623962402, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(9.278129, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF180>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED561B0; to 'JaxprTracer' at 0x000001D0EED552B0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAAED0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(9.127628326416016, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(9.127628, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF090>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED56610; to 'JaxprTracer' at 0x000001D0EED549F0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFABE20>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(8.985074996948242, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(8.985075, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF010>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55D00; to 'JaxprTracer' at 0x000001D0EED56840>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAD630>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(8.849872589111328, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(8.849873, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF080>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED562F0; to 'JaxprTracer' at 0x000001D0EED567F0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAA3E0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(8.72148323059082, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(8.721483, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF1A0>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED55BC0; to 'JaxprTracer' at 0x000001D0EED56AC0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFADEF0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(8.599411964416504, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(8.599412, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AEF70>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED569D0; to 'JaxprTracer' at 0x000001D0EED56C50>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFACFA0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(8.483207702636719, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(8.483208, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AEF40>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED567A0; to 'JaxprTracer' at 0x000001D0EED550D0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAC050>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(8.372461318969727, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(8.372461, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF190>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED56160; to 'JaxprTracer' at 0x000001D0EED56890>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAF4D0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(8.26679515838623, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(8.266795, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF030>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED56E30; to 'JaxprTracer' at 0x000001D0EED56E80>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFB0CE0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(8.165861129760742, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(8.165861, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF170>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED56D40; to 'JaxprTracer' at 0x000001D0EED56ED0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFB0CE0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(8.069341659545898, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(8.069342, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AEF20>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED56660; to 'JaxprTracer' at 0x000001D0EED56BB0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFADA90>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(7.976945400238037, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(7.9769454, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF0F0>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED57100; to 'JaxprTracer' at 0x000001D0EED57150>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAD1D0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(7.888404846191406, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(7.888405, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF060>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED56980; to 'JaxprTracer' at 0x000001D0EED56250>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFB1C30>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(7.803471565246582, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(7.8034716, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AEE70>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED57100; to 'JaxprTracer' at 0x000001D0EED55F30>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAE120>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(7.72191858291626, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(7.7219186, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF0E0>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED56CF0; to 'JaxprTracer' at 0x000001D0EED55D00>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFB0420>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(7.643535614013672, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(7.6435356, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF000>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED56E30; to 'JaxprTracer' at 0x000001D0EED56D40>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFB1E60>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(7.56812858581543, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(7.5681286, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF180>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED567A0; to 'JaxprTracer' at 0x000001D0EED56890>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAE9E0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(7.495518207550049, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(7.495518, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF140>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED56F70; to 'JaxprTracer' at 0x000001D0EED570B0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFB0CE0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(7.425539970397949, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(7.42554, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF050>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED572E0; to 'JaxprTracer' at 0x000001D0EED57330>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAC4B0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(7.358039379119873, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(7.3580394, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF120>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED57470; to 'JaxprTracer' at 0x000001D0EED55BC0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFABBF0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(7.29287576675415, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(7.292876, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AF090>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED573D0; to 'JaxprTracer' at 0x000001D0EED57240>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAB560>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "Traced<ConcreteArray(7.229916095733643, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(7.229916, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x000001D0ED9AEF90>, in_tracers=(Traced<ShapedArray(float32[1,100]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x000001D0EED57740; to 'JaxprTracer' at 0x000001D0EED56A20>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[1,100]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x000001D0EBFAA3E0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d85f73edf3f4137b4a558820d9cb5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'06335443-e68d-44e8-baa7-e52e54ab5d42': {'version"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update loop\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    \n",
    "    ######################\n",
    "    # Solution \n",
    "    gradients = grad_loss_function(x_jax, y_jax, weights, bias)\n",
    "    weights = weights - eta * gradients[0]\n",
    "    bias = bias - eta * gradients[1]\n",
    "    ######################\n",
    "    weights_history = weights_history.at[i + 1].set(weights[0])\n",
    "    bias_history = bias_history.at[i + 1].set(bias[0])\n",
    "    \n",
    "    if (verbose):\n",
    "        print('%2d. error = %f, weights = %f, %f, %f' % (i, np.sum(np.abs(error)) / n_observations, bias[0, 0], weights[0, 0], weights[0, 1]))\n",
    "plot = center_plot(\n",
    "    scatter_boundary(\n",
    "        np.array(x_inputs), \n",
    "        np.array(y_class), \n",
    "        np.array(weights_history), \n",
    "        np.array(bias_history), \n",
    "        i + 1)\n",
    "    )\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi-layer networks\n",
    "\n",
    "In the following, we define the overall architecture of the exercise to fill. The goal is to define a more advanced problem \n",
    "\n",
    "### 2-layer XOR problem\n",
    "\n",
    "In most cases, classification problems are far from being linear. Therefore, we need more advanced methods to be able to compute non-linear class boundaries. The advantage of neural networks is that the same principle can be applied in a *layer-wise* fashion. This allows to further discriminate the space in sub-regions (as seen in the course). We will try to implement the 2-layer *perceptron* that can provide a solution to the infamous XOR problem. The idea is now to have the output of the first neurons to be connected to a set of other neurons. Therefore, if we take back our previous formulation, we have the same output for the first neuron(s) $y$, that we will now term as $y^{(1)}$. Then, we feed these outputs to a second layer of neurons, which gives\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "y^{(2)}=\\sigma\\left(\\sum_{i = 1}^{n}w_{i}.y^{(1)}_{i} + b\\right)\n",
    "\\end{equation}\n",
    "$$  \n",
    "\n",
    "Finally, we will rely on the same loss $\\mathcal{L_{D}}$ as in the previous exercise, but the outputs used are $y^{(2)}$ instead of $y$. As in the previous case, we now need to compute the derivatives of the weights and biases for several layers . However, you should see that some form of generalization might be possible for any number of layer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Exercise (course)\n",
    ">   1. Perform the derivatives for the last layer specifically\n",
    ">   2. Define a generalized derivative for any previous layer\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can construct the prototypical set of XOR values by using the following code (note that this is the most simple case, but still this is typically a problem that cannot be solved by a _linear classifier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4310c29d5942ee8f35682cf0c90a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'99fbbca5-a585-48bd-a55e-a7e344cab9d9': {'version"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from cml.plot import center_plot, scatter_classes\n",
    "# Input patterns\n",
    "n_augment = 1000\n",
    "x_inputs = np.array([[-1, -1],[-1,  1],[1, -1],[1,  1]])\n",
    "y_class = np.array([0, 1, 1, 0])\n",
    "augmented_x = []\n",
    "augmented_y = []\n",
    "for x, y in zip(x_inputs, y_class):\n",
    "    augmented_x.append(x + (np.random.randn(n_augment, 2) * 0.2))\n",
    "    augmented_y.append(np.repeat(y, n_augment))\n",
    "augmented_x = np.concatenate(augmented_x)\n",
    "augmented_y = np.concatenate(augmented_y)\n",
    "# Corresponding classes\n",
    "# Initialize based on their sizes\n",
    "n_inputs = x_inputs.shape[0]\n",
    "n_outputs = 1\n",
    "# Plot the XOR problem\n",
    "plot = center_plot(scatter_classes(augmented_x, augmented_y, title = \"XOR classification\"))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Observing the problem interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb4e64d4b804cb48ccebe93786ca716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'5c88bcb8-5b99-40da-80b5-2b0371b6b73e': {'version"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cml.tasks import ClassificationLinear, ClassificationXOR\n",
    "explorer = ClassificationXOR()\n",
    "explorer.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the problem with the `scikit-learn` library\n",
    "\n",
    "As a side note, and as discussed in the previous course, there is obviously a lot of libraries that can perform the training of such networks for you directly, without understanding what is exactly going on behind the scene. A quite extensive library is `scikit-learn`, which contains already coded models and learning procedure, that will allow us to _learn_ the parameters of this unknown function.\n",
    "\n",
    "Here we will use a `MLPClassifier` model to perfom classification on standardized features that we rescale through the `LinearRegression` and that this polynomial should be of degree 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Create the MLP classifier\n",
    "classifier = MLPClassifier(alpha=1, max_iter=1000)\n",
    "# Standardize the input features\n",
    "clf = make_pipeline(StandardScaler(), classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now based on this model definition, training it can be performed with a single line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cml.data import xor_separation\n",
    "# Generate a XOR dataset\n",
    "x_inputs, y_classes = xor_separation(500, 0.1)\n",
    "# Train the MLP model\n",
    "clf.fit(x_inputs, y_classes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi-layer implementation\n",
    "\n",
    "In this exercise, we will implement the XOR classification resolution using NumPy and JAX. This classification problem cannot be solved with a simple linear classifier. Hence, we will need to use at least a 2-layer network. The minimal set of variables that will be used by your code should be the following.\n",
    "\n",
    "```Python\n",
    "x_inputs          # 2 x n matrix of random points\n",
    "y_class           # classes of the patterns \n",
    "n_hidden          # Number of hidden units\n",
    "eta               # Learning rate parameter\n",
    "momentum          # Momentum parameter (bonus)\n",
    "weights1          # 1st layer weights\n",
    "weights2          # 2nd layer weights\n",
    "mse_limit         # Sum-squared error limit\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hidden units\n",
    "n_hidden = 2\n",
    "# Learning rate parameter\n",
    "eta = 0.005\n",
    "# Momentum parameter\n",
    "momentum = 0.1\n",
    "# Sum-squared error limit\n",
    "mse_limit = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 1 - 2-layers XOR classification\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> To complete this exercise, you will need to have a basic understanding of NumPy and JAX. You can use the resources provided in the previous exercises to learn more about these libraries.\n",
    "\n",
    "We help you out by first defining the XOR classification problem to solve (and outlining some basic properties)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cml.data import xor_separation\n",
    "# Definition of our data properties\n",
    "n_observations = 500\n",
    "noise_factor = 0.1\n",
    "# Properties of our problem\n",
    "n_input = 2\n",
    "n_output = 1\n",
    "# Generate a XOR dataset\n",
    "x_inputs, y_classes = xor_separation(n_observations, noise_factor)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.scatter(x_inputs[y_classes == 0, 0], x_inputs[y_classes == 0, 1], color='red', label='Class 0')\n",
    "ax.scatter(x_inputs[y_classes == 1, 0], x_inputs[y_classes == 1, 1], color='blue', label='Class 1')\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_title('XOR problem')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also show some potential implementation of the **initialization scheme**. Note that you can later try to replace this naive implementation by some more refined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st layer weights\n",
    "weights1 = (np.random.randn(n_hidden, n_input) * 0.01)\n",
    "# 2nd layer weights\n",
    "weights2 = (np.random.randn(n_output, n_hidden) * 0.01)\n",
    "# 1st layer biases\n",
    "bias1 = (np.random.randn(n_hidden, 1) * 0.01)\n",
    "# 2nd layer biases\n",
    "bias2 = (np.random.randn(n_output, 1) * 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.1 - Implement 2-layer XOR classification with NumPy\n",
    "\n",
    "> 1. Update the forward propagation and error computation\n",
    "> 2. Update the back-propagation part to learn the weights of both layers.\n",
    "> 3. Run the learning and check your network results\n",
    "  \n",
    "*For optional questions, please look at the end of this exercise's code boxes for more information*\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2500002384185791\n",
      "Epoch 100, Loss: 0.25\n",
      "Epoch 200, Loss: 0.25\n",
      "Epoch 300, Loss: 0.25\n",
      "Epoch 400, Loss: 0.25\n",
      "Epoch 500, Loss: 0.25\n",
      "Epoch 600, Loss: 0.25\n",
      "Epoch 700, Loss: 0.25\n",
      "Epoch 800, Loss: 0.25\n",
      "Epoch 900, Loss: 0.25\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def forward(X, weights1, bias1, weights2, bias2):\n",
    "    z1 = np.dot(weights1.T, X) + bias1\n",
    "    a1 = sigmoid(z1)\n",
    "    \n",
    "    z2 = np.dot(weights2.T, a1) + bias2\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    return a1, a2\n",
    "\n",
    "def backward(X, y, a1, a2, weights1, weights2, bias1, bias2, momentum, prev_dW1, prev_dW2, prev_db1, prev_db2, eta):\n",
    "    dz2 = (a2 - y) * a2 * (1 - a2)\n",
    "    dW2 = np.dot(a1, dz2.T)\n",
    "    db2 = np.sum(dz2, axis=1, keepdims=True)\n",
    "    \n",
    "    dz1 = np.dot(weights2, dz2) * a1 * (1 - a1)\n",
    "    dW1 = np.dot(X, dz1.T)\n",
    "    db1 = np.sum(dz1, axis=1, keepdims=True)\n",
    "    \n",
    "    weights2_update = momentum * prev_dW2 - eta * dW2\n",
    "    weights1_update = momentum * prev_dW1 - eta * dW1\n",
    "    bias2_update = momentum * prev_db2 - eta * db2\n",
    "    bias1_update = momentum * prev_db1 - eta * db1\n",
    "\n",
    "    weights2 += weights2_update\n",
    "    weights1 += weights1_update\n",
    "    bias2 += bias2_update\n",
    "    bias1 += bias1_update\n",
    "\n",
    "    return weights1, weights2, bias1, bias2, weights1_update, weights2_update, bias1_update, bias2_update\n",
    "\n",
    "def train(X, y, weights1, weights2, bias1, bias2, n_hidden, n_input, n_output, momentum=0.1, mse_limit=0.002, eta=0.005, epochs=1000):\n",
    "\n",
    "    loss_history = []\n",
    "\n",
    "    weights1 = np.random.randn(n_input, n_hidden) * 0.01\n",
    "    weights2 = np.random.randn(n_hidden, n_output) * 0.01\n",
    "    bias1 = np.random.randn(n_hidden, 1) * 0.01\n",
    "    bias2 = np.random.randn(n_output, 1) * 0.01\n",
    "    \n",
    "    prev_dW1 = np.zeros_like(weights1)\n",
    "    prev_dW2 = np.zeros_like(weights2)\n",
    "    prev_db1 = np.zeros_like(bias1)\n",
    "    prev_db2 = np.zeros_like(bias2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        a1, a2 = forward(X, weights1, bias1, weights2, bias2)\n",
    "        \n",
    "        loss = mean_squared_error(y, a2)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        if loss < mse_limit:\n",
    "            print(f'Early stopping at epoch {epoch} with loss: {loss}')\n",
    "            break\n",
    "\n",
    "        weights1, weights2, bias1, bias2, prev_dW1, prev_dW2, prev_db1, prev_db2 = backward(\n",
    "            X, y, a1, a2, weights1, weights2, bias1, bias2, momentum, prev_dW1, prev_dW2, prev_db1, prev_db2, eta\n",
    "        )\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss}')\n",
    "    \n",
    "    return weights1, weights2, bias1, bias2, loss_history\n",
    "\n",
    "loss_history = []\n",
    "weights1, weights2, bias1, bias2, loss_history = train(x_inputs.T, y_classes, weights1, weights2, bias1, bias2, n_hidden, n_input, n_output, momentum, mse_limit, eta, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.plot(loss_history)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.set_title('Training loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.2 - Implement XOR classification with JAX\n",
    "\n",
    "> 1. Perform the same implementation as previously with JAX\n",
    "> 2. Implement gradient descent to optimize the weights and bias.\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2500065565109253\n",
      "Epoch 100, Loss: 0.25000008940696716\n",
      "Epoch 200, Loss: 0.25\n",
      "Epoch 300, Loss: 0.25\n",
      "Epoch 400, Loss: 0.25\n",
      "Epoch 500, Loss: 0.25\n",
      "Epoch 600, Loss: 0.25\n",
      "Epoch 700, Loss: 0.25\n",
      "Epoch 800, Loss: 0.25\n",
      "Epoch 900, Loss: 0.25\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad\n",
    "from jax import random\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + jnp.exp(-z))\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return jnp.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def forward(X, weights1, bias1, weights2, bias2):\n",
    "    z1 = jnp.dot(weights1.T, X) + bias1\n",
    "    a1 = sigmoid(z1)\n",
    "    \n",
    "    z2 = jnp.dot(weights2.T, a1) + bias2\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    return a1, a2\n",
    "\n",
    "def loss_fn(weights1, weights2, bias1, bias2, X, y):\n",
    "    _, a2 = forward(X, weights1, bias1, weights2, bias2)\n",
    "    return mean_squared_error(y, a2)\n",
    "\n",
    "def train(X, y, weights1, weights2, bias1, bias2, n_hidden, n_input, n_output, momentum=0.1, mse_limit=0.002, eta=0.005, epochs=1000):\n",
    "    loss_history = []\n",
    "\n",
    "    weights1 = random.normal(key, (n_input, n_hidden)) * 0.01\n",
    "    weights2 = random.normal(key, (n_hidden, n_output)) * 0.01\n",
    "    bias1 = random.normal(key, (n_hidden, 1)) * 0.01\n",
    "    bias2 = random.normal(key, (n_output, 1)) * 0.01\n",
    "    \n",
    "    prev_dW1 = jnp.zeros_like(weights1)\n",
    "    prev_dW2 = jnp.zeros_like(weights2)\n",
    "    prev_db1 = jnp.zeros_like(bias1)\n",
    "    prev_db2 = jnp.zeros_like(bias2)\n",
    "\n",
    "    loss_grad = grad(loss_fn, argnums=(0, 1, 2, 3))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        gradients = loss_grad(weights1, weights2, bias1, bias2, X, y)\n",
    "        dW1, dW2, db1, db2 = gradients\n",
    "\n",
    "        weights2_update = momentum * prev_dW2 - eta * dW2\n",
    "        weights1_update = momentum * prev_dW1 - eta * dW1\n",
    "        bias2_update = momentum * prev_db2 - eta * db2\n",
    "        bias1_update = momentum * prev_db1 - eta * db1\n",
    "\n",
    "        weights2 += weights2_update\n",
    "        weights1 += weights1_update\n",
    "        bias2 += bias2_update\n",
    "        bias1 += bias1_update\n",
    "\n",
    "        prev_dW2 = weights2_update\n",
    "        prev_dW1 = weights1_update\n",
    "        prev_db2 = bias2_update\n",
    "        prev_db1 = bias1_update\n",
    "\n",
    "        loss = loss_fn(weights1, weights2, bias1, bias2, X, y)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        if loss < mse_limit:\n",
    "            print(f'Early stopping at epoch {epoch} with loss: {loss}')\n",
    "            break\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss}')\n",
    "    \n",
    "    return weights1, weights2, bias1, bias2, loss_history\n",
    "\n",
    "key = random.PRNGKey(42)\n",
    "\n",
    "x_inputs = jnp.asarray(x_inputs)\n",
    "y_classes = jnp.asarray(y_classes)\n",
    "\n",
    "weights1, weights2, bias1, bias2, loss_history = train(x_inputs.T, y_classes, weights1, weights2, bias1, bias2, n_hidden, n_input, n_output, momentum, mse_limit, eta, 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.3 - Understanding properties of our implementation\n",
    "\n",
    "> 4. Perform multiple re-runs of the learning procedure (re-launching with different initializations)\n",
    ">     1. What observations can you make on the learning process?\n",
    ">     2. What happens if you initialize all weights to zeros?\n",
    ">     3. Change your initialization and regularization scheme\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Going further\n",
    "\n",
    "> The following set of questions are optionnal addendum to your previous code that allow to understand more in-depth properties about _regularization_ both for neural networks and optimization in general.\n",
    "\n",
    "> 1. (Optional) Implement the *weight decay* constraint in your network.\n",
    "> 2. (Optional) Add the *momentum* to the learning procedure.\n",
    "\n",
    "> *Weight decay* constraint\n",
    "> As nothing constrains the weights in the network, we can note that usually all weights vector given a multiplicative factor might be equivalent, which can stall the learning (and lead to exploding weights). The *weight decay* allows to regularize the learning by penalizing weights with a too wide amplitude. The idea is to add this constraint as a term to the final loss (which leads to an indirect \"pressure\" on the learning process. Therefore, the final loss will be defined as\n",
    "> $$\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_{final}=\\mathcal{L_D} + \\lambda \\sum_{l} \\sum_{i} \\sum_{j} \\left( W_{ij}^{l} \\right)^{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "> where the parameter $\\lambda$ controls the relative importance of the two terms.\n",
    "\n",
    "> *Momentum* in learning\n",
    "> Usually, in complex problems, the gradient can be very noisy and, therefore, the learning might oscillate widely. In order to reduce this problem, we can *smooth* the different gradient updates by retaining the values of the gradient at each iteration and then performing an update based on the latest gradient $\\delta_{i}^{t}$ and the gradient at the previous iteration $\\delta_{i}^{t-1}$. Therefore, a gradient update is applied as\n",
    "> $$\n",
    "\\begin{equation}\n",
    "\\delta_{final}^{t} = \\delta_{i}^{t} + m.\\delta_{i}^{t-1}\n",
    "\\end{equation}\n",
    "$$\n",
    "> with $m$ the momentum parameter, which control the amount of gradient smoothing.\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 3-layer audio classification\n",
    "\n",
    "Once again, note that the following paragraph and subsequent questions are _optional_ but should be a quite simple extension of our previous work on 2-layer networks. If you struggle with the data import mechanisms, you can look down at the PyTorch section (with a **mandatory exercise**) that will provide base code for this aspect. \n",
    "\n",
    "Finally, we will attack a complete audio classification problem and try to perform neural network learning on a set of audio files. The data structure will be the same as the one used for parts 1 and 2. As discussed during the courses, even though a 2-layer neural network can provide non-linear boundaries, it can not perform \"holes\" inside those regions. In order to obtain an improved classification, we will now rely on a 3-layer neural network. The modification to the code of section 3.2 should be minimal, as the back-propagation will be similar for the new layer as one of the two others. We do not develop the math here as it is simply a re-application of the previous rules with an additional layer (which derivatives you should have generalized in the previous exercise).  \n",
    "\n",
    "However, up until now, we only performed *binary classification* problems, but this time we need to obtain a decision rule for multiple classes. Therefore, we cannot rely on simply computing the distance between desired patterns and the obtained binary value. The idea here is to rely on the *softmax regression*, by considering classes as a vector of probabilities. The desired answers will therefore be considered as a set of *probabilities*, where the desired class is $1$ and the others are $0$ (called *one-hot* representation). Then, the cost function will rely on the softmax formulation\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathcal{L_D}(\\theta) = - \\frac{1}{m} \\left[ \\sum_{i=1}^{m} \\sum_{j=1}^{k} 1\\left\\{y^{(i)} = j\\right\\} \\log \\frac{e^{\\theta_{j}^{T} x^{(i)}}}{\\sum_{l=1}^{k} e^{ \\theta_{l}^{T} x^{(i)} }}  \\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Therefore, we compute the output of the softmax by taking \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "p(y^{(i)} = j | x^{(i)}; \\theta) = \\frac{e^{\\theta_{j}^{T} x^{(i)}}}{\\sum_{l=1}^{k} e^{ \\theta_{l}^{T} x^{(i)}} }\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "By taking derivatives, we can show that the gradient of the softmax layer is\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\nabla_{\\theta_{j}} \\mathcal{L_D}(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}{ \\left[ x^{(i)} \\left( 1\\{ y^{(i)} = j\\}  - p(y^{(i)} = j \\mid x^{(i)}, \\theta) \\right) \\right]}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweet activation functions\n",
    "\n",
    "As discussed in the course, the interest of stacking layers is that there is an _activation function_, which allows non-linear interactions between the dimensions (and avoids to only compute a single huge affine transform). Although the `sigmoid` function has been historically the most used, there has been some large developments since. Notably the `ReLU` (Rectified Linear Unit) is one of the major difference in modern networks (we will see more about that in a later course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing the Sigmoid activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "# Derivative\n",
    "def dsigmoid(a):\n",
    "    return a * (1.0 - a)\n",
    "# Function for computing the ReLU activation\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "# Derivative\n",
    "def drelu(x):\n",
    "    if (x < 0):\n",
    "        return 0\n",
    "    return 1\n",
    "# Function for computing the Tanh activation\n",
    "def tanh(x):\n",
    "    return np.tanh(x);\n",
    "# Derivative\n",
    "def dtanh(x): \n",
    "    return np.cosh(x) ^ -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we plot some simple examples of what these activation functions look like. You can try to rely on these functions in your previous training code and witness the differences in training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244afded8d284c9a8d96470072987090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'d31d12ff-5961-4e63-8bb4-27e0b3f62eb5': {'version"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bokeh.models import Div\n",
    "from bokeh.layouts import column, row\n",
    "from cml.plot import cml_figure\n",
    "# Functions to\n",
    "funcs = [('Sigmoid',sigmoid,'red'), ('Tanh',tanh,'orange'), ('ReLU',relu,'yellow')]\n",
    "# Generating the x axis\n",
    "x = np.linspace(-5, 5, 100)\n",
    "plots = []\n",
    "for (name, func, color) in funcs:\n",
    "    cur_plot = cml_figure(plot_width=400, plot_height=250, title=name)\n",
    "    cur_plot.line(x, func(x), color=color, line_width=4)\n",
    "    plots.append(cur_plot)\n",
    "plot = center_plot(column(Div(text = \"Different activation functions\", styles={'font-size': '250%'}), row(*plots)))\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding the whole network from scratch\n",
    "\n",
    "You should now have all the tools necessary to apply neural networks from scratch to a more complex problem. In the following exercise, we simply removed any guideline code, and you need to code all the procedure for training a NN and **apply it to audio data**. You will use the spectral features discussed in the previous exercise as an input.\n",
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #192841; border-color: #779ecb\">\n",
    "\n",
    "> ### Going further **(optional exercise) **\n",
    "\n",
    ">  1. Based on the previous neural network, upgrade the code to a 3-layer neural network\n",
    ">  2. Implement the *softmax regression* on top of your 3-layer network\n",
    ">  3. Use the provided code to perform classification on a pre-defined set of features\n",
    ">  4. As previously, change the set of features to assess their different accuracies\n",
    ">  5. Evaluate the neural network accuracy for all features combinations\n",
    ">  6. What happens if the learning rate is too large ? What is this phenomenon ?\n",
    ">  7. Perform a more advanced visualization of the learning process.\n",
    "  \n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `Pytorch` to enjoy life\n",
    "\n",
    "Up to now, we have been writing every operations by ourselves (in order to better understand the mathematics behind NN). However, there exists of course some simplifying libraries that provide large simplifications to this question.\n",
    "\n",
    "One of the most powerful and complete library of this sort is `Pytorch`, which has been developed for several years (even prior to the recent boom of deep learning). `Pytorch` provides a large set of pre-coded layers, but also **computational graphs** and **autograd**, which are very powerful paradigms allowing to define complex operators and automatically taking derivatives.\n",
    "\n",
    "## An (extremely) fast and dirty introduction to `Pytorch`\n",
    "\n",
    "PyTorch is a popular open-source deep learning framework based on the Torch library. It is primarily developed by Facebook AI research team, and it provides a simple and efficient way to build deep learning models. In this extremely short crash course, we will cover the basics of PyTorch, including:\n",
    "\n",
    "* Tensors\n",
    "* Automatic differentiation\n",
    "* Neural networks\n",
    "* Training a neural network on a dataset\n",
    "\n",
    "For a complete tutorial on PyTorch, please check out the [official PyTorch documentation](https://pytorch.org/tutorials/). This tutorial covers a wide range of topics, including the basics of PyTorch, building and training neural networks, working with data and dataloaders, and deploying models to production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5024],\n",
      "        [0.4881],\n",
      "        [0.4792],\n",
      "        [0.4959],\n",
      "        [0.4987],\n",
      "        [0.5074],\n",
      "        [0.5080],\n",
      "        [0.5088],\n",
      "        [0.4951],\n",
      "        [0.5049]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "a = torch.rand(10, 2)\n",
    "b = torch.rand(10, 2)\n",
    "import torch.nn as nn\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "a = a.to(device)\n",
    "b = b.to(device)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model = model.to(device)\n",
    "out = model(a)\n",
    "out = out.to(\"cpu\")\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "x = torch.ones((100, 3))\n",
    "net = nn.Sequential(\n",
    "  nn.Linear(3, 20),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(20, 1),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "l1 = nn.Linear(3, 20)\n",
    "o1 = l1(x)\n",
    "r1 = nn.ReLU()\n",
    "o2 = r1(o1)\n",
    "l2 = nn.Linear(20, 1)\n",
    "s2 = nn.Sigmoid()\n",
    "y = s2(l2(o2))\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "At its core, PyTorch is all about tensors. A tensor is a generalization of vectors and matrices to an arbitrary number of dimensions. A scalar is a 0-dimensional tensor, a vector is a 1-dimensional tensor, and a matrix is a 2-dimensional tensor.\n",
    "\n",
    "#### Creating Tensors\n",
    "We can create a PyTorch tensor from a Python list or a NumPy array using the `torch.tensor()` function, but also tensors of a specific size and/or with all zeros or all ones using the `torch.zeros()` and `torch.ones()` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# create a tensor from a Python list\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x)\n",
    "# create a tensor from a NumPy array\n",
    "y = torch.tensor(np.array([[1, 2], [3, 4]]))\n",
    "print(y)\n",
    "# create a 2x3 tensor of zeros\n",
    "z = torch.zeros((2, 3))\n",
    "print(z)\n",
    "# create a 3x2 tensor of ones\n",
    "w = torch.ones((3, 2))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor operations\n",
    "\n",
    "PyTorch tensors support a wide range of operations, including arithmetic operations like addition, subtraction, multiplication, and division, as well as more advanced operations like matrix multiplication, element-wise multiplication, and concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6,  8, 10, 12])\n",
      "tensor([ 5, 12, 21, 32])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# create two tensors\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "y = torch.tensor([5, 6, 7, 8])\n",
    "# add the two tensors\n",
    "z = x + y\n",
    "print(z)\n",
    "# element-wise multiplication\n",
    "w = x * y\n",
    "print(w)\n",
    "# matrix multiplication\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "c = torch.matmul(a, b)\n",
    "print(c)\n",
    "# concatenation\n",
    "d = torch.cat((a, b), dim=1)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic differentiation\n",
    "\n",
    "The core of PyTorch is the autograd package. It provides automatic differentiation for all operations on Tensors.\n",
    "\n",
    "PyTorch's autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backpropagation is defined by how your code is run, and that every single iteration can be different.\n",
    "\n",
    "To compute gradients, the `requires_grad` property of Tensors needs to `True` (which is the case by default). This tells PyTorch to track all operations on the Tensor. You can then call `.backward()` on a Tensor to compute the gradients with respect to that Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(11.)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = 2*x**2 + 3*x - 1\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our network\n",
    "\n",
    "When building neural networks we frequently think of arranging the computation into layers, some of which have learnable parameters which will be optimized during learning. In `PyTorch`, the `nn` package provides higher-level abstractions over raw computational graphs that are useful for building neural networks. The `nn` package defines a set of `Modules`, which are roughly equivalent to neural network layers. A `Module` receives input `Tensors` and computes output `Tensors`, but may also hold internal state such as `Tensors` containing learnable parameters. The nn package also defines a set of useful loss functions that are commonly used when training neural networks.\n",
    "\n",
    "In the following example, we use the `nn` package to show how easy it is to instantiate our previous three-layers network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Define the input dimensions\n",
    "in_size = 1000\n",
    "# Number of neurons in a layer\n",
    "hidden_size = 100\n",
    "# Output (target) dimension\n",
    "output_size = 10\n",
    "# Use the nn package to define our model and loss function.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_size, hidden_size),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(hidden_size, hidden_size),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(hidden_size, output_size),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the network\n",
    "\n",
    "Up to this point we have updated the weights of our models by manually performing the gradient descent algorithm (changing the parameters vectors). Although this is not a huge burden for simple optimization algorithms like stochastic gradient descent, in practice we often train neural networks using more sophisticated optimizers like AdaGrad, RMSProp or Adam (that we will see later in this course)\n",
    "\n",
    "The `optim` package in PyTorch abstracts the idea of an optimization algorithm and provides implementations of commonly used optimization algorithms, and greatly simplfies the training loop associated with training a neural network.\n",
    "\n",
    "For the sake of presentation we will use random inputs $\\mathbf{x}$ that should be matched with random outputs $\\mathbf{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(batch_size, in_size)\n",
    "y = torch.randn(batch_size, output_size)\n",
    "\n",
    "class MyLayer(nn.Module):\n",
    "\n",
    "    def forward():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example we optimize the model using the Adam algorithm provided by the `optim` package, based on a `MSE` loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(490.2220, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Learning rate\n",
    "learning_rate = 1e-4\n",
    "# Loss function that we will use\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "# Optimizer to fit the weights of the network\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = model(x)\n",
    "    # Compute the loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    # Before the backward pass, zero all of the network gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Backward pass: compute gradient of the loss with respect to parameters\n",
    "    loss.backward()\n",
    "    # Calling the step function to update the parameters\n",
    "    optimizer.step()\n",
    "print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Pytorch to classify audio\n",
    "\n",
    "Now that we know the main components of `Pytorch` to define and optimize networks, your assignement is to define a complete classification problem from audio data, by relying on this toolbox\n",
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.1 - Model and definition\n",
    "\n",
    ">   1. Use `Pytorch` to define a model for audio classification\n",
    ">   2. Import the audio features dataset and check that your model produces an output\n",
    "\n",
    "</div>\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 60\n",
      "Waveform shape: torch.Size([1, 50800])\n",
      "Sample rate: 8000\n",
      "Labels: [0, 0, 0, 0, 1, 1, 1, 1]\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n",
      "Waveform shape: torch.Size([1, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio.transforms as transforms\n",
    "\n",
    "# YESNO\n",
    "yesno_data = torchaudio.datasets.YESNO(\"./data\", download=True)\n",
    "\n",
    "# \n",
    "print(f\"Number of samples: {len(yesno_data)}\")\n",
    "\n",
    "# \n",
    "waveform, sample_rate, labels = yesno_data[0]\n",
    "print(f\"Waveform shape: {waveform.shape}\")\n",
    "print(f\"Sample rate: {sample_rate}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "\n",
    "# \n",
    "mel_spectrogram_transform = transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=64)\n",
    "\n",
    "# \n",
    "def preprocess(waveform):\n",
    "    spec = mel_spectrogram_transform(waveform)\n",
    "    # zero padding\n",
    "    if spec.shape[2] < 256:\n",
    "        spec = torch.cat((spec, torch.zeros(1, 64, 256 - spec.shape[2])), dim=2)\n",
    "    else:\n",
    "        spec = spec[:, :, :256]\n",
    "    # reshape to 1, 64, 256\n",
    "    spec = spec.reshape(1, 64, 256)\n",
    "    return spec\n",
    "\n",
    "for i in range(len(yesno_data)):\n",
    "    waveform, sample_rate, labels = yesno_data[i]\n",
    "    spec = preprocess(waveform)\n",
    "    print(f\"Waveform shape: {spec.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mel spectrogram shape: torch.Size([1, 64, 256])\n",
      "Mel spectrogram shape: torch.Size([1, 64, 256])\n",
      "Mel spectrogram shape: torch.Size([1, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    waveform, sample_rate, label = yesno_data[i]\n",
    "    spec = mel_spectrogram_transform(waveform)\n",
    "    # zero padding\n",
    "    if spec.shape[2] < 256:\n",
    "        spec = torch.cat((spec, torch.zeros(1, 64, 256 - spec.shape[2])), dim=2)\n",
    "    else:\n",
    "        spec = spec[:, :, :256]\n",
    "    # reshape to 1, 64, 256\n",
    "    spec = spec.reshape(1, 64, 256)\n",
    "    print(f\"Mel spectrogram shape: {spec.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YesNoClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YesNoClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 8)  # 8, yes/no\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 8 * 8)  # \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class YesNoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sample_rate, labels = self.dataset[idx]\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "        return waveform, torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# \n",
    "yesno_mel_dataset = YesNoDataset(yesno_data, transform=preprocess)\n",
    "train_loader = DataLoader(yesno_mel_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [16, 1, 1, 64, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\ml_win\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\ml_win\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[93], line 12\u001b[0m, in \u001b[0;36mYesNoClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m)  \u001b[38;5;66;03m# \u001b[39;00m\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\ml_win\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\ml_win\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\ml_win\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\ml_win\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [16, 1, 1, 64, 256]"
     ]
    }
   ],
   "source": [
    "# \n",
    "model = YesNoClassifier()\n",
    "criterion = nn.BCELoss()  # \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# \n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Pad tensors to the same size\n",
    "        max_len = max(input.size(2) for input in inputs)\n",
    "        inputs = torch.stack([torch.nn.functional.pad(input, (0, max_len - input.size(2))) for input in inputs])\n",
    "        #  (batch_size, 1, freq_bins, time_frames)\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "\n",
    "        # \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #  + \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:  # 10\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}], Loss: {running_loss / 10:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\" style=\"color:white; background-color: #013220; border-color: #03C03C\">\n",
    "\n",
    "> ### Question 1.2 - Training the model\n",
    "\n",
    ">   3. Write the optimization loop (think carefully about the _loss function_\n",
    ">   4. As previously, change the set of features to assess their different accuracies\n",
    ">   5. (Optional) Think of how you could use more complex features (time series, audio, STFT) to classify your data\n",
    "\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################\n",
    "# YOUR CODE GOES HERE\n",
    "######################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_win",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
